{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce37c340-ea2f-4595-aa8f-7ebd2255656a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7293d46c-8dda-45d1-aa08-7bb6d0c5cd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Load and Explore Data\n",
    "\n",
    "\n",
    "Welcome to the \"Load and Explore Data\" lab! In this session, you will learn essential skills in data loading and exploration using PySpark in a Databricks environment. Gain hands-on experience reading data from Delta tables, managing data permissions, computing summary statistics, and using data profiling tools to unveil insights in your Telco dataset. Let's dive into the world of data exploration!\n",
    "\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "\n",
    "In this Lab, you will learn how to:\n",
    "1. Read data from delta table\n",
    "1. Manage data permissions\n",
    "1. Show summary statistics\n",
    "1. Use data profiler to explore data frame\n",
    "    - Check outliers\n",
    "    - Check data distributions\n",
    "1. Read previous versions of the delta table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e50e8d27-7a67-4762-a7ea-784655c82fd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e46f379-175b-45f1-980e-76f00effae9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92cd1d0f-8fbd-4d20-a3ca-bacc647ae4ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Lab Setup\n",
    "\n",
    "Before starting the Lab, follow these initial steps:\n",
    "\n",
    "1. Run the provided classroom setup script. This script will establish necessary configuration variables tailored to each user. Execute the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25ce0d3a-430a-4f42-9db5-70d4d4d40640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11b800ae-280e-49d1-9c7e-8a4b482d65d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Other Conventions:**\n",
    "\n",
    "Throughout this lab, we'll make use of the object `DA`, which provides critical variables. Execute the code block below to see various variables that will be used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c70f16e-5967-4818-b70a-db882d63d081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "587b1eb3-0816-4db8-924a-286822639ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 1: Read Data from Delta Table\n",
    "\n",
    "\n",
    "+ Use Spark to read data from the Delta table into a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28c6838c-7cdd-42b7-a068-05b351d50330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Load dataset with spark\n",
    "shared_volume_name = 'telco' # From Marketplace\n",
    "csv_name = 'telco-customer-churn-missing' # CSV file name\n",
    "dataset_path = f\"{DA.paths.datasets.telco}/{shared_volume_name}/{csv_name}.csv\" # Full path\n",
    "\n",
    "## Read dataset with spark\n",
    "telco_df = spark.read.csv(dataset_path, header=\"true\", inferSchema=\"true\", multiLine=\"true\", escape='\"')\n",
    "\n",
    "table_name = \"telco_missing\"\n",
    "table_name_bronze = f\"{table_name}_bronze\"\n",
    "\n",
    "## Write it as delta table\n",
    "telco_df.write.mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable(table_name_bronze)\n",
    "telco_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef124c9c-0e86-4ac1-ae20-fe281d78d04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 2: Manage Data Permissions\n",
    "\n",
    "Establish controlled access to the Telco Delta table by granting specific permissions for essential actions.\n",
    "\n",
    "+ Grant permissions for specific actions (e.g., read, write) on the Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f857afe3-44fd-4c1d-afeb-6b4cffca3770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "---- Write query to Grant Permission to all the users to access Delta Table\n",
    "GRANT SELECT ON TABLE telco_missing_bronze TO `account users`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fb8f0de-b5de-42e2-98ab-02eeb9d357f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 3: Show Summary Statistics\n",
    "\n",
    "\n",
    "Compute and present key statistical metrics to gain a comprehensive understanding of the Telco dataset.\n",
    "\n",
    "\n",
    "+ Utilize PySpark to compute and display summary statistics for the Telco dataset.\n",
    "\n",
    "+ Include key metrics such as mean, standard deviation, min, max, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d5b34b6-09ed-45b4-aaf5-d861b093c3cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Show summary of the Data\n",
    "dbutils.data.summarize(telco_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d36d7ed4-da45-41da-86b3-6d54206cef0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 4: Use Data Profiler to Explore DataFrame\n",
    "Use the Data Profiler and Visualization Editor tools.\n",
    "\n",
    "+ Use the Data Profiler to explore the structure, data types, and basic statistics of the DataFrame.\n",
    "    - **Task 4.1.1:** Identify columns with missing values and analyze the percentage of missing data for each column.\n",
    "    - **Task 4.1.2:** Review the data types of each column to ensure they match expectations. Identify any columns that might need type conversion.\n",
    "+ Use Visualization Editor to Check Outliers and Data Distributions:\n",
    "    - **Task 4.2.1:** Create a bar chart to visualize the distribution of churned and non-churned customers.\n",
    "    - **Task 4.2.2:** Generate a pie chart to visualize the distribution of different contract types.\n",
    "    - **Task 4.2.3:** Create a scatter plot to explore the relationship between monthly charges and total charges.\n",
    "    - **Task 4.2.4:** Visualize the count of customers for each payment method using a bar chart.\n",
    "    - **Task 4.2.5:** Compare monthly charges for different contract types using a box plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf345162-e9ce-4219-802d-cf800fe8bec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Display the data and Explore the Data Profiler and Visualization Editor\n",
    "display(telco_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99bab057-c145-4449-9755-31166a9a6461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 5: Drop the Column\n",
    "Remove a specific column, enhancing data cleanliness and focus.\n",
    "\n",
    "\n",
    "+ Identify the column that needs to be dropped. For example, let's say we want to drop the 'SeniorCitizen' column.\n",
    "\n",
    "\n",
    "+ Use the appropriate command or method to drop the identified column from the Telco dataset.\n",
    "\n",
    "\n",
    "+ Verify that the column has been successfully dropped by displaying the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7ab14a5-30b2-4cee-8c9e-e1d1b6612a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Drop SeniorCitizen Column \n",
    "telco_dropped_df = telco_df.drop(\"SeniorCitizen\")\n",
    "\n",
    "## Overwrite the Delta table\n",
    "telco_dropped_df.write.mode(\"overwrite\").option(\"overwriteSchema\", True).saveAsTable(table_name_bronze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c714761b-c9ee-4ea2-a71c-38258f55700c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 6: Time-Travel to First \n",
    "\n",
    "\n",
    "Revert the Telco dataset back to its initial state, exploring the characteristics of the first version.\n",
    "\n",
    "\n",
    "+ Utilize time-travel capabilities to revert the dataset to its initial version.\n",
    "\n",
    "\n",
    "+ Display and analyze the first version of the Telco dataset to understand its original structure and content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a90c538d-5319-4880-a772-daf4d5bcf991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Extract timestamp of first version (can also be set manually)\n",
    "timestamp_v0 = spark.sql(f\"DESCRIBE HISTORY telco_missing_bronze\").orderBy(\"version\").first().timestamp\n",
    "(spark\n",
    "        .read\n",
    "        .option(\"timestampAsOf\", timestamp_v0)\n",
    "        .table(\"telco_missing_bronze\")\n",
    "        .printSchema()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f15df4d2-3a6a-49c7-ac4e-4d9061651b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##Task 7: Read previous versions of the delta table\n",
    "Demonstrate the ability to read data from a specific version of the Delta table.\n",
    "\n",
    "+ Replace the timestamp in the code with the actual version or timestamp of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8e21d40-4d89-45d8-b6d2-cb5af13eae24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "---- Show table versions\n",
    "DESCRIBE HISTORY telco_missing_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a6519dd-c3d9-4583-9980-7e89ff6ee20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Conclusion\n",
    "In this lab, you demonstrated how to explore and manipulate the dataset using Databricks, focusing on data exploration, management, and time-travel capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b550a927-a723-4c5d-9b9b-a8661fab4c79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "1.2 Lab Solution - Load and Explore Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}